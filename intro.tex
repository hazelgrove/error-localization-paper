\section{Introduction}
\label{sec:introduction}

% When a static type checker locates a type error, the hope is that the type error accurately locates a problem that is blocking progress on the task at hand. 
% However, the reality is that the type error might incorrectly locate the problem, or locate a problem irrelevant to the task at hand. In all cases, the developer must fix all type errors before . These gaps in service can  persist for hours or days at a time, such as when a key type definition is 
% modified in a way that causes multiple errors to appear throughout a large program. 
% Until \emph{all} of these errors are fixed, it may be the case that \emph{none} of the changed code paths can be tested at run-time, 
% and many helpful language services are not fully functional \cite{HazelnutSNAPL}.

Modern programming environments provide 
a variety of semantic services that require statically analyzing the type and binding structure of the program being edited, e.g. semantic navigation, type hints, semantic code completion, and automated refactoring. 
These semantic services are often packaged into language servers that front-end
editors and editor extensions can interface with\todo{cites}.

The problem that animates this paper is that during program editing, 
it is common for the program being edited to be ill-typed. These ill-typed states sometimes persist over long periods of time, e.g. a change to a type definition can cause errors to arise at all usage sites in a large program, which can take hours or days to address. Language servers often exhibit gaps in service during these periods, because in the conventional formal account of type systems, only well-typed programs have a well-defined type and binding structure. As soon as a type error occurs \emph{anywhere}, the program is formally meaningless \emph{everywhere}.



Developers demand that these gaps in service be minimized or eliminated, so there has been considerable practical interest in (1)~\textbf{type error localization}: mechanisms for directing the developer to 
the location(s) in a program that may be erroneous, and (2) \textbf{type error recovery}: 
mechanisms that allow the language server to continue past the first localized error and provision downstream semantic services even when there in the presence of localized type errors.
Indeed, essentially all widely-used programming systems have some support for type error 
localization, e.g. via compiler error messages or the language server.
Many also attempt recovery of certain services in certain situations. 
However, the design of these mechanisms has evolved in some part as folklore, because type system definitions have remained silent about how to reason in the presence of errors. Different type checkers for the same language can and do attempt to localize, report, and recover from these errors in different ways, with little in the way of unifying theory. 

Consider, for example, the following program in a typed functional language with only local type inference, for simplicity, 
\begin{lstlisting}[numbers=none]
let x = 
  if f(y) then 1 else true
in 
  x + 1
\end{lstlisting}
There are several certain errors here: \li{f} and \li{y} are unbound, and the two branches of the conditional expression have inconsistent types. There may or may not be an error in the use of \li{x} on Line 4, depending on which branch type is intended.

A type checker with no support for error localization or recovery would simply report that this program is ill-typed, and indeed this behavior is enough to satisfy the language specification, if given in the conventional style (e.g. following the simply typed lambda calculus and its derivatives). A more helpful and common approach is to localize the error that causes type checking to initially fail, e.g. here the system might report that the variable \li{f} is unbound and highlight its location in the error message or with an editor decoration (i.e. without attempting recovery).
This is the approach taken in many production type checkers, e.g. XXX.\todo{examples}

A first attempt at error recovery might continue past this first error to also report that \li{y} is unbound, then ignore the fact that guard of the conditional cannot therefore be confirmed to be a boolean expression and nevertheless continue into its branches. Here, the system might observe that the two branches have inconsistent types, \li{int} and \li{bool}. How should this error be localized? There are many possible approaches here.
One approach would be to assume that the first branch is correct, so the error can be localized to the second branch. This is \emph{ad hoc}, and the system might just as well assume the second branch is correct, localizing the error to the first branch.
A third approach might be to report the inconsistency between the two types as an error localized to the conditional expression itself. 

Which choice is made affects how error recovery will proceed into the body of the let expression, \li{x + 1}. In particular, if the system assumes that the conditional should have \li{int} type, then \li{x : int} and no error needs to be reported here. 
If the system assumes it should have \li{bool} type, then an error does need to be reported. 
If the system reports only the inconsistency between the two branches, then it is not clear what type \li{x} should have, and so it becomes difficult to continue to recover.


(compare Elm/OCaml/Haskell and Hazel directly?)



For these reasons, accurate type error localization and robust type error recovery have been a topic of considerable practical interest. 



One reason for this is 
that type system definitions typically only define the conditions under which an expression is well-typed, e.g. in the style of the simply typed lambda calculus and its derivatives. When there is a type error anywhere in the program, it is everywhere meaningless according to definitions in this style, i.e. there is no direct specification for how to reason within an erroneous program. 

The primary contribution of this paper is to provide these missing theoretical foundations for type error localization and recovery. 
Start assuming a system with local type inference / bidirectional typing, marked lambda calculus(Give judgement forms right off the bat??) 
(Mention gradual typing here?)

We build on the foundation of the Hazelnut type system, which allows for local type inconsistencies to be placed within a non-empty hole, 
e.g. $1 + false$ is meaningless but $1 + \{false\}$ can be given type Num. In other words, the non-empty holes serves as a membrane around type inconsistencies, here between the expected type, Num, and the synthesized type, Bool. Problems:

1. does not handle every kind of error that can arise, e.g. inconsistent branch types, unbound variables, etc.

2. does not provide a general account for how to correctly place the non-empty holes -- in that paper, they assume that a structure editor will be used and show how the structure editor can determine whether a non-empty hole is needed at the cursor after an edit action, but edits that might cause non-local errors to appear are undefined. users can also manually mark these locations, similar to Agda's non-empty holes. (Examples?)

To solve both of these problems, we establish totality of marking -- we prove it to be total (and to insert only marks, without making any other changes), i.e. it must handle 
every possible syntactically well-formed program and thus every error. Mechanized in Agda.

Marking does not rely on a structure editor, so it is suitable as a foundational calculus for language servers supporting editors of any 
design, both text editors (with syntax error recovery, a well-studied topic that we consider outside of the scope of this paper) and structure editors. To support this claim, we have implemented the calculus in a version of Hazel built atop tylr, which features both a text editor with explicit syntax for holes (a la Agda, GHC, etc.) and a textual structure editor with syntax error recovery via automatic hole insertion. Maximal liveness guarantee! 

Additional foundational contribution, we have also defined two versions of Hazelnut that eliminate the undefined behavior just mentioned. Composed with marking, this solves the problem. Also briefly consider incremental remarking in the style of Hazelnut.

As we go, we'll discuss various localization design decisions that the language designer should consider when specifying the marked type system for their language. Overall, though, our work validates the folklore that systems that rely on local type inference tend to have an easier time deciding how to localize type errors (Pierce paper). Many modern languages feature local type inference, including .... 
However, non-local constraint-based type inference is also a common language feature, and it is known to substantially complicate error localization and recovery. 
Heuristic approaches based on ML-based approaches, weighting, etc.
In this paper, we consider an alternative approach to incorporating non-local constraints. Rather than ...

