\section{Introduction}
\label{sec:introduction}

% When a static type checker locates a type error, the hope is that the type error accurately locates a problem that is blocking progress on the task at hand. 
% However, the reality is that the type error might incorrectly locate the problem, or locate a problem irrelevant to the task at hand. In all cases, the developer must fix all type errors before . These gaps in service can  persist for hours or days at a time, such as when a key type definition is 
% modified in a way that causes multiple errors to appear throughout a large program. 
% Until \emph{all} of these errors are fixed, it may be the case that \emph{none} of the changed code paths can be tested at run-time, 
% and many helpful language services are not fully functional \cite{HazelnutSNAPL}.

Modern programming environments provide developers with 
various semantic services, such as type hints, semantic navigation, semantic code completion, and automated refactoring, that require statically reasoning about the type and binding structure of the program as it is being edited. 
% These semantic services are often packaged into language servers\todo{cites}.
The problem is that the program being edited can be ill-typed, sometimes for long periods of time. 
For example, when the developer changes an important type definition, errors might arise at dozens of usage sites in a large program, which could take hours or days to address. Semantic services often exhibit gaps in service during these periods \cite{HazelnutSNAPL}, because in the conventional formal account of type systems, only well-typed programs have a well-defined type and binding structure. As soon as a type error occurs \emph{anywhere}, the program is formally meaningless \emph{everywhere}.

Developers benefit when these gaps in service are minimized or eliminated, so there has long been considerable practical interest in (1)~\textbf{type error localization}: mechanisms for directing the developer to 
the location(s) in a program that may be erroneous, and (2) \textbf{type error recovery}: 
mechanisms that allow the language server to optimistically recover from localized errors and continue to provide downstream semantic services, ideally throughout the program.

Essentially all widely-used programming systems have some support for type error 
localization, e.g. via compiler error messages or user interface affordances fed by data from a language server.\todo{cites}
Many also attempt recovery of certain services in certain situations, discussed below. 
However, type error localization and recovery mechanisms has developed idiosyncratically, often as folklore amongst tool designers. Different type checkers or language servers, even for the same language, localize and recover from type errors in different ways, with little in the way of unifying theory of the sort that grounds the design of modern type systems themselves.

Consider, for example, the following program written in a typed functional language with, for now, only local type inference \cite{pierce}: 
\begin{lstlisting}[numbers=none]
let x = 
  if f(y) then 1 else true
in 
  x + 1
\end{lstlisting}
A type checker with no support for error localization or recovery at all would simply report that this program is ill-typed, because a type cannot be derived for it according to the type system specification, if given in the conventional style (e.g. following the simply typed lambda calculus and its derivatives). 

The more common and practical approach is to localize the first error that causes type checking to fail and emit an error message\todo{cites} (which can help, though studies suggest that developers primarily use location information). In this example, such a system might report that the variable \li{f} is unbound and communicate its location, e.g. using editor decorations. 
This is the approach taken in many production type checkers, e.g. XXX.\todo{examples}

A language server with support for type error recovery might continue past this initial error to also report that \li{y} is unbound. To recover further, the system might optimistically ignore the fact that guard of the conditional cannot be confirmed to be a boolean expression and continue into its branches, observing that they have inconsistent types, \li{int} and \li{bool}. 

There are several potential approaches to localizing this inconsistency. 
One approach would be to assume, arbitrarily, that the first branch is correct, so the error can be localized to the second branch, or \emph{vice versa}. 
Heuristic approaches have been developed to make choices like these less arbitrary, e.g. by inspecting the recent editing history \todo{cite}, or training a machine learning model \todo{cite}. 
Another approach is to localize the inconsistency between the two branches to the conditional expression itself. This entirely avoids needing to heuristically decide which branch is correct. 

This localization decision affects how the system recovers as it proceeds into the let body, \li{x + 1}. 
If localization assumes that the \li{then} branch is correct, then \li{x : int} and there is no error to report here.
If the \li{else} branch is chosen, then \li{x : bool} and an error can be reported (though this error might mislead the programmer if this earlier localization step was incorrect). 
If instead the inconsistency is localized to the conditional expression as a whole, then it is not obvious which type to assign to \li{x} at all. (Mention gradual typing here?)

This exercise demonstrates that type error localization and recovery mechanisms engage in non-trivial reasoning and make choices that are not fully specified by the type system itself. 
The first contribution of this paper is to address this problem by developing formal foundations for type error localization and recovery. 
Start assuming a system with local type inference / bidirectional typing, marked lambda calculus(Give judgement forms right off the bat??) 
(Mention gradual typing here?)

We build on the foundation of the Hazelnut type system, which allows for local type inconsistencies to be placed within a non-empty hole, 
e.g. $1 + false$ is meaningless but $1 + \{false\}$ can be given type Num. In other words, the non-empty holes serves as a membrane around type inconsistencies, here between the expected type, Num, and the synthesized type, Bool. Problems:

1. does not handle every kind of error that can arise, e.g. inconsistent branch types, unbound variables, etc.

2. does not provide a general account for how to correctly place the non-empty holes -- in that paper, they assume that a structure editor will be used and show how the structure editor can determine whether a non-empty hole is needed at the cursor after an edit action, but edits that might cause non-local errors to appear are undefined. users can also manually mark these locations, similar to Agda's non-empty holes. (Examples?)

To solve both of these problems, we establish totality of marking -- we prove it to be total (and to insert only marks, without making any other changes), i.e. it must handle 
every possible syntactically well-formed program and thus every error. Mechanized in Agda.

Marking does not rely on a structure editor, so it is suitable as a foundational calculus for language servers supporting editors of any 
design, both text editors (with syntax error recovery, a well-studied topic that we consider outside of the scope of this paper) and structure editors. To support this claim, we have implemented the calculus in a version of Hazel built atop tylr, which features both a text editor with explicit syntax for holes (a la Agda, GHC, etc.) and a textual structure editor with syntax error recovery via automatic hole insertion. Maximal liveness guarantee! 

Additional foundational contribution, we have also defined two versions of Hazelnut that eliminate the undefined behavior just mentioned. Composed with marking, this solves the problem. Also briefly consider incremental remarking in the style of Hazelnut.

As we go, we'll discuss various localization design decisions that the language designer should consider when specifying the marked type system for their language. Overall, though, our work validates the folklore that systems that rely on local type inference tend to have an easier time deciding how to localize type errors (Pierce paper). Many modern languages feature local type inference, including .... 
However, non-local constraint-based type inference is also a common language feature, and it is known to substantially complicate error localization and recovery. 
Heuristic approaches based on ML-based approaches, weighting, etc.
In this paper, we consider an alternative approach to incorporating non-local constraints. Rather than ...

