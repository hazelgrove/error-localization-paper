\section{Introduction}
\label{sec:introduction}

% When a static type checker locates a type error, the hope is that the type error accurately locates a problem that is blocking progress on the task at hand. 
% However, the reality is that the type error might incorrectly locate the problem, or locate a problem irrelevant to the task at hand. In all cases, the developer must fix all type errors before . These gaps in service can  persist for hours or days at a time, such as when a key type definition is 
% modified in a way that causes multiple errors to appear throughout a large program. 
% Until \emph{all} of these errors are fixed, it may be the case that \emph{none} of the changed code paths can be tested at run-time, 
% and many helpful language services are not fully functional \cite{HazelnutSNAPL}.

Contemporary programming environments provide 
a variety of semantic services that require statically analyzing the type and binding structure of the program being edited, e.g. semantic navigation, type hints, semantic code completion, and automated refactoring. However, during the editing process,
it is common for programs to be ill-typed. 

Language designers typically specify static type systems as a collection of rules 
stating conditions under which an expression can be judged to be well-typed,
i.e. completely free of type errors. 
 is well-supported 
by these definitions. 

When there is a type error, however, these definitions are inadequate. It is therefore left as an implementation decision (1) type error localization: how to localize and explain the type error, and (2) type error recovery: how to recover from the error to find other simultaneous errors and to continue to provision various semantic services, which would often still useful even in the presence of errors. 

Consider, for example, 

let x = 
  if f(y) then 1 else true
in 
  x + 1


(compare Elm/OCaml/Haskell and Hazel directly?)

Different language servers or typecheckers for the same language can and do attempt to localize, report, and recover from these errors in different ways, with little in the way of unifying theory. 

For these reasons, accurate type error localization and robust type error recovery have been a topic of considerable practical interest. 
Indeed, essentially all widely-used programming environments (often via an underlying language server) have some support for type error 
localization and many also attempt recovery of certain services in certain situations. However, the design of these systems has evolved in some part as folklore, as type system definitions have remained silent.


One reason for this is 
that type system definitions typically only define the conditions under which an expression is well-typed, e.g. in the style of the simply typed lambda calculus and its derivatives. When there is a type error anywhere in the program, it is everywhere meaningless according to definitions in this style, i.e. there is no direct specification for how to reason within an erroneous program. 

The primary contribution of this paper is to provide these missing theoretical foundations for type error localization and recovery. 
Start assuming a system with local type inference / bidirectional typing, marked lambda calculus(Give judgement forms right off the bat??) 
(Mention gradual typing here?)

We build on the foundation of the Hazelnut type system, which allows for local type inconsistencies to be placed within a non-empty hole, 
e.g. $1 + false$ is meaningless but $1 + \{false\}$ can be given type Num. In other words, the non-empty holes serves as a membrane around type inconsistencies, here between the expected type, Num, and the synthesized type, Bool. Problems:

1. does not handle every kind of error that can arise, e.g. inconsistent branch types, unbound variables, etc.

2. does not provide a general account for how to correctly place the non-empty holes -- in that paper, they assume that a structure editor will be used and show how the structure editor can determine whether a non-empty hole is needed at the cursor after an edit action, but edits that might cause non-local errors to appear are undefined. users can also manually mark these locations, similar to Agda's non-empty holes. (Examples?)

To solve both of these problems, we establish totality of marking -- we prove it to be total (and to insert only marks, without making any other changes), i.e. it must handle 
every possible syntactically well-formed program and thus every error. Mechanized in Agda.

Marking does not rely on a structure editor, so it is suitable as a foundational calculus for language servers supporting editors of any 
design, both text editors (with syntax error recovery, a well-studied topic that we consider outside of the scope of this paper) and structure editors. To support this claim, we have implemented the calculus in a version of Hazel built atop tylr, which features both a text editor with explicit syntax for holes (a la Agda, GHC, etc.) and a textual structure editor with syntax error recovery via automatic hole insertion. Maximal liveness guarantee! 

Additional foundational contribution, we have also defined two versions of Hazelnut that eliminate the undefined behavior just mentioned. Composed with marking, this solves the problem. Also briefly consider incremental remarking in the style of Hazelnut.

As we go, we'll discuss various localization design decisions that the language designer should consider when specifying the marked type system for their language. Overall, though, our work validates the folklore that systems that rely on local type inference tend to have an easier time deciding how to localize type errors (Pierce paper). Many modern languages feature local type inference, including .... 
However, non-local constraint-based type inference is also a common language feature, and it is known to substantially complicate error localization and recovery. 
Heuristic approaches based on ML-based approaches, weighting, etc.
In this paper, we consider an alternative approach to incorporating non-local constraints. Rather than ...

